{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMXKLtUNXaRXUsgowUIck0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnewtont/ModCloth_Recommendation_System/blob/main/rsp_pre_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "svo4xDK7cMIO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.sparse.linalg import svds\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Makes utility matrix\n",
        "def make_um(df):\n",
        "    um_train = df.pivot_table(index = 'user_id', columns = 'item_id', values = 'rating')\n",
        "    um_train.fillna(0, inplace = True)\n",
        "    return um_train"
      ],
      "metadata": {
        "id": "hWopCVOb7dE-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Makes the model using SVD\n",
        "def build_model_SVD(um, n, kay, p_val):\n",
        "    R = um.values\n",
        "    R_mean = np.mean(R, axis = 1)\n",
        "    R_mean = R_mean.reshape(-1,1)\n",
        "    R_demeaned = R - R_mean\n",
        "\n",
        "    U, sigma, Vt = svds(R_demeaned, k = n) # This gets applied to the *demeaned* ratings matrix\n",
        "    sigma = np.diag(sigma)\n",
        "\n",
        "    R_red = U@sigma@Vt\n",
        "    R_red = R_red + R_mean # Un-demean the ratings matrix\n",
        "\n",
        "    um_red = pd.DataFrame(R_red, columns = um.columns, index = um.index)\n",
        "    cs_red = um_red.corr(method = 'spearman')\n",
        "\n",
        "    nn_red = NearestNeighbors(n_neighbors = kay, p = p_val)\n",
        "    nn_red.fit(cs_red)\n",
        "\n",
        "    return nn_red"
      ],
      "metadata": {
        "id": "k5SHtXUDEr2U"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Builds a model using SVD and then evaluates each user's linear combination to\n",
        "# obtain their recommended items.\n",
        "def recommend_items_SVD(UM_test, user_LC, CS_train_M, dict, n, kay, p_val):\n",
        "    rec_items = np.zeros((len(UM_test.index), kay))\n",
        "    model = build_model_SVD(UM_test, n, kay, p_val)\n",
        "\n",
        "    for user in user_LC.index:\n",
        "        user_reshaped = np.array(user_LC.loc[user]).reshape((1,len(user_LC.loc[user])))\n",
        "        items = model.kneighbors(user_reshaped, return_distance = False)\n",
        "        rec_items[dict[user],:] = np.array(CS_train_M.columns)[items]\n",
        "    return rec_items"
      ],
      "metadata": {
        "id": "Qf8moArOEms6"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates the number of matches between our actual data and the model\n",
        "def num_of_matches(actual_data, rec_items_df):\n",
        "    counter = 0\n",
        "    for user in actual_data['user_id'].unique():\n",
        "        items_actual = actual_data.loc[actual_data['user_id'] == user, 'item_id']\n",
        "        items_pred = rec_items_df.loc[user]\n",
        "        counter += len(set(items_actual).intersection(set(items_pred)))\n",
        "    return counter"
      ],
      "metadata": {
        "id": "7FyzdR1H5QIj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_RMSE(um, n_list):\n",
        "    RMSE_dict = {}\n",
        "    for n in n_list:\n",
        "        R = um.values\n",
        "        R_mean = np.mean(R, axis = 1)\n",
        "        R_mean = R_mean.reshape(-1,1)\n",
        "        R_demeaned = R - R_mean\n",
        "\n",
        "        U, sigma, Vt = svds(R_demeaned, k = n) # This gets applied to the *demeaned* ratings matrix\n",
        "        sigma = np.diag(sigma)\n",
        "\n",
        "        R_red = U@sigma@Vt\n",
        "        R_red = R_red + R_mean # Un-demean the ratings matrix\n",
        "\n",
        "        RMSE = (((((R - R_red)**2).sum().sum()) / (R.shape[0] * R.shape[1]))**0.5)\n",
        "        RMSE_dict[n] = RMSE\n",
        "    return RMSE_dict"
      ],
      "metadata": {
        "id": "jvVS8lBK_eeP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load our filtered data\n",
        "df = pd.read_csv('/content/df_modcloth_filtered.csv')"
      ],
      "metadata": {
        "id": "lvIF7buHcRtK"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will train-test split our data using 50/50 stratification."
      ],
      "metadata": {
        "id": "Yoehautp6OBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size = 0.5, stratify = df['item_id'])"
      ],
      "metadata": {
        "id": "Zk6vjlQU51Bm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will then create the utility matrices and calculate Spearman's correlation for the full data, the training data, and the test data."
      ],
      "metadata": {
        "id": "b1kXEcSM8hPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "um = make_um(df)\n",
        "cs = um.corr(method = 'spearman')"
      ],
      "metadata": {
        "id": "3IXA-0td6Zpg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "um_train = make_um(train)\n",
        "cs_train = um_train.corr(method = 'spearman')"
      ],
      "metadata": {
        "id": "ubmUSI_C76jP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "um_test = make_um(test)\n",
        "cs_test = um_test.corr(method = 'spearman')"
      ],
      "metadata": {
        "id": "SqrGSNoe76_v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing the values of Spearman's correlation of the training and test data into their own dataframes to ensure the matrix multiplication is done properly when calculating each user's linear combination thereafter."
      ],
      "metadata": {
        "id": "WAnnV6Sq9J_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cs_M = pd.DataFrame(cs, columns = um.columns, index = um.columns)\n",
        "cs_train_M = pd.DataFrame(cs_train, columns = um_train.columns, index = um_train.columns)\n",
        "cs_test_M = pd.DataFrame(cs_test, columns = um_test.columns, index = um_test.columns)"
      ],
      "metadata": {
        "id": "Agy3xyYg8NKA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the linear combination of each user by multipling the utility matrix of the test data and the values of Spearman's correlation of the training data."
      ],
      "metadata": {
        "id": "U1q9kLjm8xhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_LC = um_test@cs_train_M"
      ],
      "metadata": {
        "id": "sBqcFBUU8TZ-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_LC_f = um@cs_M"
      ],
      "metadata": {
        "id": "eMCkMz41AKp1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_dict = {}\n",
        "for u in range(len(user_LC.index)):\n",
        "  user_dict[u] = user_LC.index[u]\n",
        "user_dict = dict((v,k) for k,v in user_dict.items())"
      ],
      "metadata": {
        "id": "jNejBfTE9JI6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_dict_f = {}\n",
        "for u in range(len(user_LC_f.index)):\n",
        "  user_dict_f[u] = user_LC_f.index[u]\n",
        "user_dict_f = dict((v,k) for k,v in user_dict_f.items())"
      ],
      "metadata": {
        "id": "nfAxr3KWA0ZN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will build several models using different numbers of singular values and utilizing L2 norm."
      ],
      "metadata": {
        "id": "_XTToXMCVLWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVD_dfs = []\n",
        "for v in [150, 200, 250, 300, 350, 400, 410, 425]:\n",
        "    SVD_dfs.append(pd.DataFrame(recommend_items_SVD(um_test, user_LC, cs_train_M, user_dict, v, 10, 2), index = user_dict.keys()))"
      ],
      "metadata": {
        "id": "o2zzfZyo4or5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine the best model, we will use a simple metric where we obtain the number of matches between the model and the test data."
      ],
      "metadata": {
        "id": "ZM1wj6OdNgT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_matches_list = [num_of_matches(test, d) for d in SVD_dfs]\n",
        "num_of_matches_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4xdH8m_5Hts",
        "outputId": "9b1c995c-7f49-4367-d89f-2c64c7ef8341"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[28471, 31677, 36024, 36527, 35273, 24905, 16697, 9012]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using 300 singular values yields the highest number of matches."
      ],
      "metadata": {
        "id": "mYaUNoK6NxbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "find_RMSE(um_test, [150, 200, 250, 300, 350, 400, 410, 425])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkblGVQn_Yf2",
        "outputId": "d611484d-07a4-4146-9905-23c019d437fa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{150: 0.11694898618322215,\n",
              " 200: 0.09220406287725107,\n",
              " 250: 0.07272982418493837,\n",
              " 300: 0.05572772770216872,\n",
              " 350: 0.03960055127367815,\n",
              " 400: 0.022028825810890874,\n",
              " 410: 0.017799197684599175,\n",
              " 425: 0.009877427505372538}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check for singular values between 300 and 350 and see if they improve our model. (In this case, 310, 320, 330, and 340)"
      ],
      "metadata": {
        "id": "U8pnIxQvOQ9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(range(310, 341, 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCdNhUu5O3Ax",
        "outputId": "75b71cf7-7eb4-4055-dcef-cd60dc93d932"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[310, 320, 330, 340]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVD_dfs_2 = []\n",
        "for v in list(range(310, 341, 10)):\n",
        "    SVD_dfs_2.append(pd.DataFrame(recommend_items_SVD(um_test, user_LC, cs_train_M, user_dict, v, 10, 2), index = user_dict.keys()))"
      ],
      "metadata": {
        "id": "c6U0pvsxOkxC"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_matches_list_2 = [num_of_matches(test, d) for d in SVD_dfs_2]\n",
        "num_of_matches_list_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4YtCFSRP3im",
        "outputId": "28f632d4-cb03-4a03-b43f-63402f83b139"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[35820, 35570, 35067, 34545]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of singular values of 310, 320, 330, and 340 did not improve our model."
      ],
      "metadata": {
        "id": "B3IxZX56SVvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's observe our results using L1 norm instead of L2 norm."
      ],
      "metadata": {
        "id": "xUes0JoSU2cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVD_dfs_L1 = []\n",
        "for v in [150, 200, 250, 300, 350, 400, 410, 425]:\n",
        "    SVD_dfs_L1.append(pd.DataFrame(recommend_items_SVD(um_test, user_LC, cs_train_M, user_dict, v, 10, 1), index = user_dict.keys()))"
      ],
      "metadata": {
        "id": "K41WUZoRU7e-"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_matches_list_L1 = [num_of_matches(test, d) for d in SVD_dfs_L1]\n",
        "num_of_matches_list_L1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snIuaXRIVC-A",
        "outputId": "d9c014cd-7db6-4a2b-cbe2-92f71940a3ef"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4941, 3264, 3828, 2999, 2056, 993, 585, 1539]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using L1 norm drastically reduces the number of matches, therefore using L2 norm is more optimal."
      ],
      "metadata": {
        "id": "y2KI3iUIaEvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify our train-test model validation, we will now build the model on the entire dataset and compare it to itself."
      ],
      "metadata": {
        "id": "gQWlkVEuN6_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVD_dfs_full = []\n",
        "for v in [150, 200, 250, 300, 350, 400, 410, 425]:\n",
        "    SVD_dfs_full.append(pd.DataFrame(recommend_items_SVD(um, user_LC_f, cs, user_dict_f, v, 10, 2), index = user_dict_f.keys()))"
      ],
      "metadata": {
        "id": "q0kOxvD-AFo-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_matches_list_full = [num_of_matches(df, d) for d in SVD_dfs_full]\n",
        "num_of_matches_list_full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgV9Cq7pASMF",
        "outputId": "e927d2f7-1d97-4264-e6de-31d843f0694b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[29421, 37057, 54726, 65142, 60317, 49655, 39560, 20500]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_RMSE(um, [150, 200, 250, 300, 350, 400, 410, 425])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPBg6brSAcMD",
        "outputId": "12b05dd0-1387-4db6-c94f-dad5f8fb553d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{150: 0.128778485257336,\n",
              " 200: 0.1019257880438485,\n",
              " 250: 0.08059295336375218,\n",
              " 300: 0.061961617379721494,\n",
              " 350: 0.04433289670423865,\n",
              " 400: 0.02500844225436355,\n",
              " 410: 0.020314003417670517,\n",
              " 425: 0.011552216980782718}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to note that despite our root mean squared error decreasing as the number of the singular values increases, it does not always guarantee a better model.<br>\n",
        "As with our train-test split validation, using 300 singular values on the entire dataset yields the best model."
      ],
      "metadata": {
        "id": "qjrDaaQ9TSAq"
      }
    }
  ]
}